2012-12-12, Philipp Haller

## The problem

* we mix actors, futures, threads, latches...
* poor tool support for diagnosing concurrency issues

## Actors + X

### X = futures

#### State Capture

~~~ { .scala }
var state = 0

def receive = {
  case Request(x) => future {
    handleRequest(x, state) // 1. race condition between this and ChangeState
                            // 2. state is not correctly published for transfer between threads
  }
  case ChangeState(newState) =>
    state = newState
}
~~~

How do we fix it?

~~~ { .scala }
  case Request(x) => 
    // recommended pattern: store all state for the future in vals
    val currentState = state
    future {
      handleRequest(x, currentState)
    }
~~~

#### Sender Capture

~~~ { .scala }
def receive = {
  case Request(x) => future {
    val res = handleRequest(x)
    sender ! Response(res) // sender might have changed by the time we send response
  }
}
~~~

Solution:

we can capture the sender before forking off future, but there is also another pattern:

~~~ { .scala }
def receive = {
  case Request(x) => future {
    val res = handleRequest(x)
    Response(res)
  } pipeTo sender
}
~~~

### X = threads

#### Exchanging data between Actors and Threads

  * `Promise` -> `Future`
  * Blocking queue
  * ask pattern: `val fut = actor ? msg` (uses `Future`)
  * `akka.actor.ActorDSL.Inbox`:

~~~ { .scala }
// in our thread:
implicit val i = ActorDSL.inbox()
someActor ! someMsg // replies will go to 'i'
val reply = i.receive() // blocks
val doubleReply = i.select(5.seconds) { case x: Int => 2 * x } // blocks, but times out
~~~

#### Thread-safe map

~~~ { .scala }
var state = Map[K, V]()

def receiv = {
  case Put(k, v) =>
    state += (k -> v)
    sender ! AckPut
  case Get(k) =>
    sender ! state.get(k)
}
~~~

Why wrap map in an actor? Use `ConcurrentHashMap` instead, it's more efficient. Or, even better `ParTrieMap`, which is non-blocking, does snapshotting and supports parallel operations.

#### Thread locals

Work with threads, but not with actors or futures which are not bound to a single thread.

### X = Shared memory

* don't do it, but if you need to:
* prefer sharing immutable data
* for mutable adhere to Java Memory Model

## Async + Blocking APIs

### Scala + Java futures

~~~ { .scala }
val futs: List[JFuture[String]] = // list of 4000 Java futures

val upperCased = for (fut <- futs) yield future {
  fut.get(10, TimeUnit.SECONDS).toUpperCase // blocks threads in thread pool
}
~~~

The thread pool to run these futures has 4 threads on 4-core machine, if 2000 of these take 10 secs each, we'll block for 1.5h.

How do we fix it?

~~~ { .scala }
val futs: List[JFuture[String]] = // list of 4000 Java futures

val upperCased = for (fut <- futs) yield future {
  // scala.concurrent.blocking tells the thread pool that we are running 
  // code that can block indefinitely, so thread pool will leave (or spin off) 
  // some spare worker threads to handle non-blocking work
  blocking {
    fut.get(10, TimeUnit.SECONDS).toUpperCase
  }
}
~~~

With scala 2.10 or Akka 2.0, if we use Scala futures, this is not a problem:

~~~ { .scala }
val futs: List[Future[String]] = // list of 4000 Scala futures
val upperCased = for (fut <- futs) yield fut.map(_.toUpperCase) // runs fine
~~~

### Forcing managed blocking from implementers of our API

API design trick (requires scala 2.10):

~~~ { .scala }
trait Awaitable[+T] {
  def result(atMost: Duration)
            (implicit permit: CanAwait): T
}

package concurrent {
  @implicitNotFound("Use the 'Await' object")
  sealed trait CanAwait

  private[concurrent] object AwaitPermission extends CanAwait

  object Await {
    def result[T](awaitable: Awaitable[T], ...): T = 
      blocking(awaitable.result(atMost)(awaitPermission))
  }
}
~~~
