# Making Big Data Small: Streaming Algorithms in Scala

2012-09-12, Noel Welsh

**B**ig **D**ata? That is Hadoop and map/reduce. We're talking here about something different: data sets bigger than our resources can handle in one go.

### Demands

* scalable
* reak time (not batch, like Hadoop)
* simple to implement

### Streaming Algorithms

* process data in one pass
* have small space requirements (e.g. O(log(log n)))
* limited computation requirements per item (typically O(1))

But:

* give approximate answers

### Hash Functions

* deterministic
* uniform distribution
* bit values are independent (any subset of bits is equally good approximation)

In practice, use Murmur Hash 3. Scala 2.10 provides `scala.util.hashing`, look into Guava if we more algorithms are needed.

### [Bloom Filters](Bloom filter)

* a set (i.e. have I seen this user before?)
* ~5 times smaller than corresponding hash set
* there is a chance of false positives ("in set" answer even though item is not in set), but guarantee of no false negatives

Idea: bit set. _index = hash(data) mod m_; bit at index represents the item. But: there will be many ccllisions. How do we improve the confidence? Use multiple has functions:

_i<sub>1</sub> = h<sub>1</sub>(data) mod m_

_i<sub>2</sub> = h<sub>2</sub>(data) mod m_

More hashing functions -> better chance of no false positives. We can adjust the probability by setting the size of bit array, i.e. bits per element. E.g. to get 0.05 probability of false positive we need 6.2 bits/element.

Nice properties: union is a bitwise or, intersection an and, trivial to parallelise and distribute.

Optimisation: use MH3 and run the hash function twice, with different seeds; then interpolate k values between the obtained values.

### Distinct Values

(i.e.: how many distinct users do we have?)

* Flajolet-Martin sketches (LogLog, HyperLogLog)
* optimal algorithm published in 2010, but is complex

#### k-Min Values

_index = hash(data) / maxHash_ gives us a point in 0..1 range. Then calculate average distance between the points. But: storing all points would be pointless! So: just store a subset, e.g. just the minimum value, and check its distance from 0. This, however, is very noisy, so we can improve on this by storing k smallest values; then the average distance is _largest value stored/k_.

For k = 1024 the error is in the order of 2.5%. It also has the nice properties of Bloom Filter: we can do union, intersection and difference in the natural manner!

### Frequent Items

(i.e. who are the most active users?)\

#### Space Saver

* store _k_ tuples (item, count)
* when item is observed:
    - if in set, increase the count
    - if not, replace the lowest-count item with observed item

There's high error rate for uniform data, but there this kind of data is not interesting for this type of analysis.

### Libraries and Resources

* [Clearstream stream-lib](https://github.com/clearspring/stream-lib)
* [Noel's Scala library](https://github.com/noelwelsh/fleet)
* [Alex Smola's course](http://alex.smola.org/teaching/berkeley2012/streams.html)